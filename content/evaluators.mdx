---
title: "You're Missing The Point of Evaluators"
publishedAt: "2024-03-31"
summary: "AI systems should drive desired user outcomes."
---

Evaluators have become a hot topic in the AI community, with techniques proposed by experts like Emil and Jason gaining significant attention. However, despite the buzz, many people seem to be missing the fundamental point of Evaluators.

It's a common misinterpretation that Evaluators are the true measure of quality. In reality, they serve as a proxy for output quality. When multiple Evaluators are combined, accounting for the magnitude and directionality of each Evaluator becomes a complex task.

Evaluators exist on a spectrum, ranging from objective to subjective. The more subjective an Evaluator is, such as those used in LLM evaluations, the more frequently it needs to be reviewed by humans and aligned with human preferences.

The benefits of Evaluators are twofold: first, they provide objective measures of quality; second, and more importantly, they can be used in development. If it weren't for the latter, Evaluators would be far less useful, as businesses would likely prioritize user outcomes instead.

Tools like Autoblox allow developers to use Evaluators both in production and in development. This enables continuous alignment of LLM evaluations with human preferences. Over time, businesses can develop an understanding of the magnitude and directionality of Evaluators in relation to the metrics that truly matter to them.

In essence, the point of Evaluators is not to serve as the ultimate measure of quality, but rather to act as a useful proxy that can be employed throughout the development process. By understanding this fundamental principle and leveraging tools that facilitate the effective use of Evaluators, businesses can better align their AI systems with the outcomes they desire.
